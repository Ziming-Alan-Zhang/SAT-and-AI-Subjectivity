To reach my conclusion, I actually made two assumptions: 
1). SAT is a logic test, and a pure logical approach is able to solve SAT problems; 
2). Sentence-transformers are rational and objective, and no subjective intentions will be included while embedding.

Then, if AI is objective, it can perform well in solving SAT problems; if AI is actually subjective, it may misinterpret the information delivered by SAT problems, therefore do problems wrong. This is useful to discuss
whether AI performs better in humanities or science. 
